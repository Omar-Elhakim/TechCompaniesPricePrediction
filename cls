[33mcommit 8e2367927c50af54e0790002a8034544b708da8b[m[33m ([m[1;36mHEAD -> [m[1;32mginger[m[33m, [m[1;31morigin/master[m[33m, [m[1;31morigin/ginger[m[33m, [m[1;31morigin/HEAD[m[33m, [m[1;32mmaster[m[33m)[m
Author: Omar Ahmed Medhat <omarelhakim@icloud.com>
Date:   Tue Apr 22 18:37:11 2025 +0200

    Linked all datasets (#7)
    
    * Added the feature selection
    
    * Null or NaN isn't encoded, imputation works
    
    * formatting
    
    * Linked all the datasets except the founders into one, then applied the same operations.
    Updated the TODO List
    
    * remove linker because we took the wanted code and applied it to the main.ipynb
    
    * formatting

[33mcommit 68937ba1ac582cd5dfaa00b15fa15f1197186957[m
Author: OmarTebry <119633006+OmarTebry@users.noreply.github.com>
Date:   Tue Apr 22 14:27:44 2025 +0200

    imputation. (#4)
    
    * imputation.
    
    * added imputation function.

[33mcommit 33940401ff702798a41d4356d6228da607aaecf6[m
Author: Omar Watany <66807664+OmarWatany@users.noreply.github.com>
Date:   Tue Apr 22 01:15:50 2025 +0200

    encoding text data (#3)

[33mcommit 90b379e1cdb32b5afcfac3b41e30a445657bb3e7[m
Author: Omar Ahmed Medhat <omarelhakim@icloud.com>
Date:   Mon Apr 21 15:50:43 2025 +0200

    processed all CSVs (#2)
    
    * update challenges
    
    * saving
    
    * created functions to validate the links in the dataset , updated challenges , added notes
    
    * dropping columns that doesn't contain any valid link
    
    * created a notebook that links all the CSVs into one , don't know if we would need it
    
    * Formatting
    
    * fixing error in data , more preprocessing
    
    * 2araf , just to prove that I tried to scrap twitter followers
    
    * Replace matplotlib with plotly, organize the notebook as possible: process each csv on its own, remove more columns, categorize some data, and more
    
    * filtered all dfs , removed all the unneeded columns , now only the important columns are here.
    Next step: process the data to enter the model
    
    * formatting
    
    * Update challenges: remove the ones we passed

[33mcommit 4bd078120342bbf79d877b79aa6fe5bbaedc9f09[m
Author: Omar Ahmed Medhat <omarelhakim@icloud.com>
Date:   Sun Apr 20 17:19:19 2025 +0200

    Started proccessing the links (#1)
    
    * update challenges
    
    * saving
    
    * created functions to validate the links in the dataset , updated challenges , added notes
    
    * dropping columns that doesn't contain any valid link
    
    * created a notebook that links all the CSVs into one , don't know if we would need it
    
    * Formatting
    
    * fixing error in data , more preprocessing

[33mcommit 22d277b32caea1ffe2a00d34f038529e47b3eddb[m
Author: Omar-Elhakim <omarelhakim@icloud.com>
Date:   Tue Apr 15 15:42:08 2025 +0200

    Formatting and tanzeem

[33mcommit b28216870c28f22bed5ada486fa21558d706cccf[m
Author: Omar-Elhakim <omarelhakim@icloud.com>
Date:   Tue Apr 15 15:37:32 2025 +0200

    Added datasets , created the main file
